{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serg_pashkov/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/serg_pashkov/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import neighbors, model_selection, ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.DataFrame()\n",
    "negative = pd.DataFrame()\n",
    "\n",
    "positive = pd.read_csv(\"positive.csv\",sep=';',names= ['id','date','login','tweet','y','nReply','nRetvit','nFavorite'\n",
    "                                                    ,'nUserMsgAmount','nFollowers','nFriends','nLists'])\n",
    "\n",
    "negative = pd.read_csv(\"negative.csv\",sep=';',names= ['id','date','login','tweet','y','nReply','nRetvit','nFavorite'\n",
    "                                                      ,'nUserMsgAmount','nFollowers','nFriends','nLists'])\n",
    "all_tweets = pd.DataFrame()\n",
    "all_tweets = pd.concat([positive.head(3000),negative.head(3000)],ignore_index=True)\n",
    "all_tweets = all_tweets.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выравниваем регистр\n",
    "def lower(str):\n",
    "    return str.encode('utf-8').lower()\n",
    "all_tweets['tweet'] = all_tweets.tweet.apply(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Разбиваем строку и удаляем обращения\n",
    "def splitstring(str):\n",
    "    words = []\n",
    "    for i in re.split('[;,.,\\n,\\s,:,-,+,(,),=,/,«,»,@,\\d,!,?,\"]',str):\n",
    "        if len(i) > 1:\n",
    "            if re.match('@.*',i) == None:\n",
    "                words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets['Words'] = all_tweets.tweet.apply(splitstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 4200, 1800, 1800)\n"
     ]
    }
   ],
   "source": [
    "#Разбиваем на выборки\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(all_tweets.Words, all_tweets.y, test_size = 0.3)\n",
    "print(x_train.size,y_train.size,x_test.size,y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем словарь\n",
    "def WordsDic(dataset):\n",
    "    WD = []\n",
    "    for i in dataset.index:\n",
    "        for j in xrange(len(dataset[i])):\n",
    "            if dataset[i][j] in WD:\n",
    "                None\n",
    "            else:\n",
    "                WD.append(dataset[i][j])\n",
    "    return WD\n",
    "\n",
    "words = WordsDic(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Векторизируем текст\n",
    "train_matrix = np.zeros((len(x_train),len(words)))\n",
    "\n",
    "for i in xrange(train_matrix.shape[0]):\n",
    "    for j in x_train[x_train.index[i]]:\n",
    "        if j in words:\n",
    "            train_matrix[i][words.index(j)]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 9.06 µs\n",
      "0.525476190476\n",
      "{'n_neighbors': 1, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "%time\n",
    "param_grid = {'n_neighbors': np.arange(1,8), 'p': [1,2]}\n",
    "estimator_kNN = neighbors.KNeighborsClassifier()\n",
    "optimazer_kNN = GridSearchCV(estimator_kNN, param_grid, cv = 3)\n",
    "optimazer_kNN.fit(train_matrix, y_train)\n",
    "\n",
    "print optimazer_kNN.best_score_\n",
    "print optimazer_kNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 10 µs, total: 15 µs\n",
      "Wall time: 31 µs\n",
      "0.656428571429\n",
      "{'min_samples_split': 8, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "%time\n",
    "param_grid = {'n_estimators': np.arange(20,101,10), 'min_samples_split': np.arange(4,11, 1)}\n",
    "estimator_tree = ensemble.RandomForestClassifier()\n",
    "optimazer_tree = GridSearchCV(estimator_tree, param_grid, cv = 3)\n",
    "optimazer_tree.fit(train_matrix, y_train)\n",
    "\n",
    "print optimazer_tree.best_score_\n",
    "print optimazer_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Векторизируем текст\n",
    "test_matrix = np.zeros((len(x_test),len(words)))\n",
    "for i in xrange(test_matrix.shape[0]):\n",
    "    for j in x_test[x_test.index[i]]:\n",
    "        if j in words:\n",
    "            test_matrix[i][words.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес: 0.666666666667\n",
      "kNN: 0.519444444444\n"
     ]
    }
   ],
   "source": [
    "print u'Случайный лес:', accuracy_score(optimazer_tree.best_estimator_.predict(test_matrix), y_test)\n",
    "print u'kNN:', accuracy_score(optimazer_kNN.best_estimator_.predict(test_matrix), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TweetForest.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохраняем модель\n",
    "joblib.dump(optimazer_tree, 'TweetForest.pkl')\n",
    "joblib.dump(words, 'words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Используем модель\n",
    "\n",
    "clf = joblib.load('TweetForest.pkl')\n",
    "words = joblib.load('words.pkl')\n",
    "\n",
    "input_data = [ u'Круто, классно, обожаю, отлично, супер =)',\n",
    "             u'Ненавижу эту сковородку, треснуло днище',\n",
    "             u'На улице дождь, отстой',\n",
    "             u'Завтра будет хорошая погода и мы пойдем на пикник',\n",
    "             u'Ваша машинка ниочем']\n",
    "\n",
    "inputDF = pd.DataFrame()\n",
    "inputDF['tweet'] = input_data\n",
    "inputDF['tweet'] = inputDF.tweet.apply(lambda x: x.lower())\n",
    "inputDF['words'] = inputDF.tweet.apply(splitstring)\n",
    "X = inputDF['words']\n",
    "\n",
    "\n",
    "test_matrix = np.zeros((len(inputDF),len(words)))\n",
    "for i in xrange(test_matrix.shape[0]):\n",
    "    for j in X[X.index[i]]:\n",
    "        if j in words:\n",
    "            test_matrix[i][words.index(j)]+=1\n",
    "            \n",
    "predicted = clf.predict(test_matrix)\n",
    "label_names = {1:u'Положительный', -1:u'Отрицательный'}\n",
    "\n",
    "for tweet, rating in zip(input_data, predicted):\n",
    "    print(u'\\n{} ----> {}'.format(label_names.get(rating), tweet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
