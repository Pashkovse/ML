{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Корреляции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_cols_corr (data):\n",
    "    corr_data=[]\n",
    "    for i, lhs_column in enumerate(data.columns):\n",
    "        for j, rhs_column in enumerate(data.columns):\n",
    "            if i >= j:\n",
    "                continue\n",
    "        \n",
    "            corr, p = stats.wilcoxon(data[lhs_column], data[rhs_column])\n",
    "            corr_data.append([lhs_column, rhs_column, corr, p])\n",
    "    return corr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>corr</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C4.5</td>\n",
       "      <td>C4.5+m</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.010757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C4.5+cf</td>\n",
       "      <td>C4.5+m+cf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.022909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4.5</td>\n",
       "      <td>C4.5+m+cf</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.015906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.5+m</td>\n",
       "      <td>C4.5+cf</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.046333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4.5+m</td>\n",
       "      <td>C4.5+m+cf</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.327826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4.5</td>\n",
       "      <td>C4.5+cf</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.861262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A          B  corr         p\n",
       "0     C4.5     C4.5+m   6.5  0.010757\n",
       "5  C4.5+cf  C4.5+m+cf  10.0  0.022909\n",
       "2     C4.5  C4.5+m+cf  11.0  0.015906\n",
       "3   C4.5+m    C4.5+cf  17.0  0.046333\n",
       "4   C4.5+m  C4.5+m+cf  22.0  0.327826\n",
       "1     C4.5    C4.5+cf  43.0  0.861262"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AUCs.txt',delimiter='\\t')\n",
    "\n",
    "corr_data = dataset_cols_corr(data.drop(['Unnamed: 0'],axis=1))\n",
    "\n",
    "df = pd.DataFrame.from_records(corr_data)\n",
    "df.columns = ['A', 'B', 'corr', 'p']\n",
    "df.sort_values(by='corr', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корреляция Пирсона \n",
    "Мера линейной зависимости между 2 случайными величинами. Неустойчива к выбросам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918785225254219"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.corr()\n",
    "pearsonr(data['C4.5'],data['C4.5+m'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корреляция Спирмена \n",
    "Мера силы монотонной взаимосвязи = кор. Пирсона между рангами наблюдений. Более устойчив к выбросам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956043956043955"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(data['C4.5'],data['C4.5+m'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корреляция Мэтьюса\n",
    "... бинарными переменными. Для сравнения меток и предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef([0,1,1,0],[1,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки гипотез:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.109"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 203 из 718 + 239 из 515\n",
    "a = 718\n",
    "b = 203\n",
    "c = 515\n",
    "d = 239\n",
    "mcc = (a*d - b*c)/math.sqrt((a+b)*(a+c)*(b+d)*(c+d))\n",
    "round(mcc, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Коэффициент V Крамера \n",
    "... категориальными переменными. Для расчета нужно сформировать таблицу сопряженности и посчитать значение статистики Хи квадрат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293.68311039689746"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingencyTable = np.array([[197, 111, 33], [382, 685, 331], [110, 342, 333]])\n",
    "hi_square_koef = chi2_contingency(contingencyTable)[0]\n",
    "hi_square_koef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А потом вычислить сам коэффициент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2412013934500338"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = sum([sum(x) for x in contingencyTable])\n",
    "kramer_v = np.sqrt(chi2_contingency(contingencyTable)[0] / (n * 2))\n",
    "kramer_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER. Поправка Бонферрони\n",
    "Для множественной проверки гипотез. Вероятность совершить хотя бы 1 ошибку 1 рода. Достигаемый уровень значимости всех гипотез сравнивается с alpha / m. Если он меньше, то гипотеза отвергается. При использовании данного метода вероятность ошибки 1 рода ограничивается гораздо более низкой величиной, чем α, что увеличивает вероятность ошибки 2 рода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER. Метод Холма\n",
    "Для множественной проверки гипотез. Из достигаемых уровней значимости составляется вариационный ряд. Сравниваем самый маленький уровень с alpha/m, если он больше, то принимается эта гипотеза и все следующие. Если нет, то отвергается и процедура продолжается, но сравнивается уже с alpha / (m-1) и т.д. Данный метод всегда лучше Бонферрони."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(df['p'], \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm') \n",
    "reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDR. Метод Бенджамини-Хохберга\n",
    "Для множественной проверки гипотез. Повышает точность, мощность, вероятность ошибки 1 рода. Используется вариационный ряд, только сравнения начинаются с другого конца. Выбирается самый большой p-val, если он меньше alpha/m то все отвергается. В ином случае процедура продолжается, но уже c alpa*i/m и тд. Применяется только когда выборки независимы. Используется повсеместно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False,  True])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(df['p'], \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh') \n",
    "reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ влияния признаков на результат. Для начала прочитаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceb</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>religion</th>\n",
       "      <th>idlnchld</th>\n",
       "      <th>knowmeth</th>\n",
       "      <th>usemeth</th>\n",
       "      <th>evermarr</th>\n",
       "      <th>agefm</th>\n",
       "      <th>heduc</th>\n",
       "      <th>urban</th>\n",
       "      <th>electric</th>\n",
       "      <th>radio</th>\n",
       "      <th>tv</th>\n",
       "      <th>bicycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>catholic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>protestant</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>spirit</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>other</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ceb  age  educ    religion  idlnchld  knowmeth  usemeth  evermarr  agefm  \\\n",
       "0    0   18    10    catholic       4.0       1.0      1.0         0    NaN   \n",
       "1    2   43    11  protestant       2.0       1.0      1.0         1   20.0   \n",
       "2    0   49     4      spirit       4.0       1.0      0.0         1   22.0   \n",
       "3    0   24    12       other       2.0       1.0      0.0         0    NaN   \n",
       "4    3   32    13       other       3.0       1.0      1.0         1   24.0   \n",
       "\n",
       "   heduc  urban  electric  radio   tv  bicycle  \n",
       "0    NaN      1       1.0    1.0  1.0      1.0  \n",
       "1   14.0      1       1.0    1.0  1.0      1.0  \n",
       "2    1.0      1       1.0    1.0  0.0      0.0  \n",
       "3    NaN      1       1.0    1.0  1.0      1.0  \n",
       "4   12.0      1       1.0    1.0  1.0      1.0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "botswana_df = pd.read_csv('botswana.tsv', delimiter='\\t')\n",
    "botswana_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "botswana_df['nevermarr'] = np.where(botswana_df['agefm'].isnull(),1,0) \n",
    "botswana_df.drop('evermarr',1,inplace=True)\n",
    "botswana_df['agefm'].fillna(0,inplace=True)\n",
    "botswana_df.heduc = botswana_df.apply(lambda x: -1 if (x.nevermarr == 1 and pd.isnull(x.heduc)) else x.heduc, axis=1)\n",
    "botswana_df['idlnchld_noans'] = np.where(botswana_df['idlnchld'].isnull(),1,0) \n",
    "botswana_df['heduc_noans'] = np.where(botswana_df['heduc'].isnull(),1,0) \n",
    "botswana_df['usemeth_noans'] = np.where(botswana_df['usemeth'].isnull(),1,0) \n",
    "botswana_df['idlnchld'].fillna(-1,inplace=True)\n",
    "botswana_df['heduc'].fillna(-2,inplace=True)\n",
    "botswana_df['usemeth'].fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель и проанализируем ее характеристики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     345.0\n",
      "Date:                Fri, 07 Sep 2018   Prob (F-statistic):               0.00\n",
      "Time:                        20:00:49   Log-Likelihood:                -7732.1\n",
      "No. Observations:                4348   AIC:                         1.550e+04\n",
      "Df Residuals:                    4328   BIC:                         1.563e+04\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                 -1.0263      0.266     -3.863      0.000      -1.547      -0.506\n",
      "religion[T.other]         -0.0830      0.078     -1.067      0.286      -0.235       0.069\n",
      "religion[T.protestant]    -0.0149      0.078     -0.192      0.848      -0.167       0.137\n",
      "religion[T.spirit]        -0.0191      0.071     -0.268      0.789      -0.159       0.121\n",
      "age                        0.1703      0.004     38.627      0.000       0.162       0.179\n",
      "educ                      -0.0724      0.007     -9.924      0.000      -0.087      -0.058\n",
      "idlnchld                   0.0760      0.015      5.236      0.000       0.048       0.104\n",
      "knowmeth                   0.5564      0.174      3.190      0.001       0.215       0.898\n",
      "usemeth                    0.6473      0.052     12.478      0.000       0.546       0.749\n",
      "agefm                     -0.0604      0.010     -6.174      0.000      -0.080      -0.041\n",
      "heduc                     -0.0551      0.009     -6.126      0.000      -0.073      -0.037\n",
      "urban                     -0.2137      0.046     -4.667      0.000      -0.303      -0.124\n",
      "electric                  -0.2685      0.072     -3.732      0.000      -0.410      -0.128\n",
      "radio                     -0.0235      0.053     -0.446      0.656      -0.127       0.080\n",
      "tv                        -0.1451      0.082     -1.766      0.077      -0.306       0.016\n",
      "bicycle                    0.2139      0.048      4.412      0.000       0.119       0.309\n",
      "nevermarr                 -2.2393      0.202    -11.082      0.000      -2.635      -1.843\n",
      "idlnchld_noans             0.6539      0.216      3.029      0.002       0.231       1.077\n",
      "heduc_noans               -0.8724      0.191     -4.556      0.000      -1.248      -0.497\n",
      "usemeth_noans              0.7652      0.213      3.590      0.000       0.347       1.183\n",
      "==============================================================================\n",
      "Omnibus:                      224.411   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              859.014\n",
      "Skew:                           0.003   Prob(JB):                    2.93e-187\n",
      "Kurtosis:                       5.178   Cond. No.                         361.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('ceb ~ age + educ + religion + idlnchld + knowmeth + usemeth +'\\\n",
    "                    'agefm + heduc + urban + electric + radio + tv + bicycle + nevermarr + idlnchld_noans +'\\\n",
    "                    'heduc_noans + usemeth_noans', \n",
    "             data=botswana_df)\n",
    "fitted = model.fit(cov_type='HC1')\n",
    "print fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По p-value видно что показатели религии, радио и тв слабо влияют на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = smf.ols('ceb ~ age + educ  + idlnchld + knowmeth + usemeth +'\\\n",
    "                    'agefm + heduc + urban + electric + bicycle + nevermarr + idlnchld_noans +'\\\n",
    "                    'heduc_noans + usemeth_noans', \n",
    "             data=botswana_df)\n",
    "fitted2 = model2.fit(cov_type='HC1')\n",
    "print fitted2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Breusch-Pagan test: p=%s' % sms.het_breushpagan(fitted.resid, fitted.model.exog)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка гипотезы о том, что качество моделей одинаково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"F=%f, p=%f, k1=%f\" % fitted.compare_f_test(fitted2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
